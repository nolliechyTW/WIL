## Token
- **Tokenization**: The process of converting text into tokens.
- **Token Embedding**: A numerical representation of a token in a high-dimensional space where similar tokens are closer to each other.
- **Token Efficiency**: Different models have varying capacities for understanding and generating text based on the tokens they process. More advanced models may derive more meaning from fewer tokens, affecting cost efficiency. For instance, GPT-4 is more efficient in understanding context and generating relevant outputs with fewer tokens compared to GPT-3.
- **Optimization Strategies**: Techniques like dynamic tokenization (adjusting the granularity of tokenization based on the task) and pruning (reducing the model size without significant loss of performance) can optimize the cost-to-performance ratio. Additionally, careful selection of what data to process (e.g., trimming unnecessary parts of text) can reduce token count and associated costs.

## Machine Learning
- **Supervised Learning**: A type of ML where the model is trained on labeled data.
- **Unsupervised Learning**: ML without labeled data, focusing on finding patterns within the data.

## Deep Learning
- **Convolutional Neural Networks (CNNs)**: Best for image recognition and video analysis.
- **Recurrent Neural Networks (RNNs)**: Suited for sequential data such as text and speech.

## Artificial Intelligence (AI)
- **Natural Language Processing (NLP)**: Enables machines to understand and interpret human language.
- **Computer Vision**: Allows machines to interpret and make decisions based on visual data.

## Model
- **Training**: The process of feeding data into a model so it can learn to make predictions.
- **Inference**: The process of using a trained model to make predictions on new, unseen data.